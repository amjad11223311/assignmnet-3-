{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355f6755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Amgad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Amgad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.47229334689892727\n",
      "Topic: 0 \n",
      "Words: 0.008*\"q\" + 0.005*\"presid\" + 0.005*\"armenian\" + 0.005*\"new\" + 0.004*\"state\" + 0.004*\"team\" + 0.004*\"year\" + 0.004*\"nation\" + 0.004*\"game\" + 0.004*\"first\"\n",
      "Topic: 1 \n",
      "Words: 0.023*\"db\" + 0.010*\"use\" + 0.009*\"drive\" + 0.007*\"card\" + 0.006*\"one\" + 0.006*\"run\" + 0.006*\"mov\" + 0.005*\"disk\" + 0.005*\"power\" + 0.005*\"get\"\n",
      "Topic: 2 \n",
      "Words: 0.014*\"would\" + 0.011*\"one\" + 0.009*\"peopl\" + 0.009*\"think\" + 0.008*\"like\" + 0.008*\"go\" + 0.008*\"get\" + 0.007*\"know\" + 0.007*\"make\" + 0.006*\"say\"\n",
      "Topic: 3 \n",
      "Words: 0.022*\"x\" + 0.018*\"use\" + 0.012*\"key\" + 0.009*\"encrypt\" + 0.008*\"file\" + 0.007*\"program\" + 0.006*\"system\" + 0.006*\"inform\" + 0.005*\"avail\" + 0.005*\"chip\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# AMJAD ALMASSRI - IS01081643\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "data = pd.read_csv('news_dataset.csv', usecols=['text'])\n",
    "\n",
    "data.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = [word for word in text.lower().split() if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "data['processed_text'] = data['text'].apply(preprocess)\n",
    "\n",
    "dictionary = corpora.Dictionary(data['processed_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in data['processed_text']]\n",
    "\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)\n",
    "\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data['processed_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "\n",
    "print(f'Coherence Score: {coherence_lda}')\n",
    "\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\nWords: {topic}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d18f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
